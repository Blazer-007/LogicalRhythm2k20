{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Important Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import math\nimport datetime\nimport seaborn as sns\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport pandas_profiling as pp\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import f1_score,classification_report\nimport plotly.figure_factory as ff\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.model_selection import train_test_split,GridSearchCV\n\nprint('Import Success')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/Tow-Mater-Labs/train.csv\")\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#info of the training set.\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Profile Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pp.ProfileReport(df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After studying the profile report for various Features, the observations that can be drawn about the data are :\n1. **About Data :**<br>\n    - Data contains a total of 15 features (including the label 'accepted').<br>\n    - Out of these Features, 8 features are categorical, 6 are continuous and 1 is the unique 'id' for each indivisual(datapoint).\n    \n2. **About Features :**<br>\n  \n      - **id :** Unique identification for a particular person(datapoint). Is of no use in predicting the label.\n        \n      - **blood_group,gender :** Balanced categorical feature - has all categories equally distributed.\n        \n      - **age,annual_premium,policy_sales_channel,vintage,mother_age,father_age :**<br>\n           a. Continuous Features of the data.<br>\n           b. annual_premium has very large values in comparison to other features,might need to normalize.\n           \n      - **driving_license :** highly skewed for class 1. i.e most of the datapoints have value 1 for this feature.**Might be helpful in predicting the labels.**\n      \n      - **Region_code :** not much of an informative feature. Though it is also partially imbalanced for **region 28.**\n      \n      - **Previously_insured,Vehicle_damage :** These are balanced features. **There might be a correlation between these features and the label, hence can be important.**\n      \n      - **Vehicle_Age :** It contains three categories, out of which two are balanced, while third category is quite less in frequency.(might have a correlation with the label)\n      \n      - **accepted :** This is the label that we need to predict. It his highly skewed(imbalanced for class - 0)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imbalance in data labels : 'accepted'\nplt.figure(figsize=(16,6))\nsns.countplot(x = 'accepted',data = df_train)\nplt.title('frequency of people accepting the insurance',fontweight = 'bold')\nplt.show()\nprint('accepted Details :')\nprint(df_train['accepted'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## - Checking and removal of NULL values"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df_train.columns:\n    print( i+\" \\t: \" +str(df_train[i].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## - Checking for categories of Categorical Features."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Gender', 'Region_Code', 'Vehicle_Age', 'Vehicle_Damage','Previously_Insured']\nfor column in columns:\n    print(\"{} : {}\".format(column,np.unique(df_train[column])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Custom Encoding of columns ~ 'Previously_Insured'"},{"metadata":{},"cell_type":"markdown","source":"### - Encoding \"Region_Code\""},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#frequency of categories of 'Region_Code'\nprint(df_train['Region_Code'].value_counts(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clearly we can see that the frequency of categories in this feature is not uniform,hence encoding all of the columns of this feature, might not be fruitful.\n#So, Under a generalization, I have encoded only those categories with frequency > 2600.\n\n#encoding \"Region_Code\"\n\ncol_to_create = np.unique(df_train['Region_Code'])\nvals = list(col_to_create)\n\nencoding_column = ['Region_Code']\nunique_sets = []\n\nfor column in encoding_column:\n    \n    unique_vals = vals\n    unique_set = []\n    \n    for val in unique_vals:\n        \n        encode = []\n        for element in df_train[column]:\n            \n            if element==val:\n                encode.append(1)\n            else:\n                encode.append(0)\n                \n        #filtering under frequency generalization.\n        if sum(encode)>2600:\n            \n            unique_set.append(column+\"_\"+str(val))\n            df_train[column+\"_\"+str(val)] = encode\n            \n    unique_sets.append(unique_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Region_codes with frequency > 2600.\nprint(unique_sets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Encoding \"Vehicle_Age\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-Hot kind of encoding for this feature might lead to different correlation of this feature with the label.\n#Hence, this feature has been encoded, on the basis of average of age that the category says: e.g : '< 1 Year' == 0.5 , '1-2 Year' == 1.5 and '> 2 Years' == 2.5\n#Custom Encoding\n\nencode = []\n\nfor val in df_train['Vehicle_Age']:\n    \n    if val=='< 1 Year':\n        encode.append(0.5)\n    elif val == '1-2 Year':\n        encode.append(1.5)\n    else:\n        encode.append(2.5)\ndf_train['Vehicle_Age'] = encode\ndf_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Encoding \"Vehicle_Damage\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#This Feature contains two classes : \"Yes\",\"No\"\n#encoding has been done as : \"Yes\" : 1,\"No\" : 0\n\nencode = []\nfor val in df_train['Vehicle_Damage']:\n    \n    if val == 'Yes':\n        encode.append(1)\n    else:\n        encode.append(0)\ndf_train['Vehicle_Damage'] = encode\ndf_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Encoding \"Gender\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#This feature contains two classes : \"Male\",\"Female\"\n#encoding has been done as : \"Male\" : 1,\"Female\" : 0\n\nencode = []\nfor val in df_train['Gender']:\n    \n    if val == \"Male\":\n        encode.append(1)\n    else:\n        encode.append(0)\ndf_train['Gender'] = encode\ndf_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Why not encode \"bloog_group\" Feature ?\n\n- **Since, there is no visible variation between various Blood_Groups and people accepting to take insurance. So, i didn't encode \"blood_group\" Feature.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#count of vechile damage in data(w.r.t to acceptance) \nplt.figure(figsize=(16,6))\nax = sns.countplot(x = 'blood_group',hue = 'accepted',data = df_train,palette=['#432371',\"#FAAE7B\"])\nplt.title('frequency of blood Groups w.r.t them accepting to insure',fontweight = 'bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## - Vehicle_Damage w.r.t acceptance"},{"metadata":{"trusted":true},"cell_type":"code","source":"#count of vechile damage in data(w.r.t to acceptance) \nplt.figure(figsize=(16,6))\nax = sns.countplot(x = 'Vehicle_Damage',hue = 'accepted',data = df_train)\nplt.title('frequency of those having damaged vehicle w.r.t those who accept to insure',fontweight = 'bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion:\n### - **Those whose vehicle is damaged is most-likely to say 'NO' to acceptance of insurance.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#count of people who got there vehicle previously insured(w.r.t acceptance)\nplt.figure(figsize=(16,6))\nax = sns.countplot(x = 'Previously_Insured',hue = 'accepted',data = df_train,palette=['#FFC300',\"#FF5733\"])\nplt.title('frequency of people who had gotten their vehicle previously insured w.r.t them accepting to insure the vechile',fontweight = 'bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion :\n- <h3>Above plot shows that, if the person has got his vehicle previously insured : He won't accept the insurance."},{"metadata":{},"cell_type":"markdown","source":"## Encoded_Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{},"cell_type":"markdown","source":"## - Correlation matrix for dataset ~ \"Region Code\""},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 600\ntitle = '<b>Correlation Matrix for the dataset:</b>'\ncolors = 'Viridis'\n\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = ['Age', 'Driving_License','Previously_Insured', 'Annual_Premium',\n           'Policy_Sales_Channel', 'Vintage', 'Vehicle_Age', 'Vehicle_Damage',\n           'Gender','accepted']\n#-------------------------------------------------------------------------#\n\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat//0.0001)/10000\ncorrelation_mat_norm = (correlation_mat//0.01)/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra></extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))//1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **From the above Correlation Matrix, we can observe that , features like -** <br>\n#### - Vehicle_Age,Vehicle_Damage show relatively high +ve correlation with 'accepted'(final label).\n#### - Age also shows +ve correlation with 'accepted'.\n#### - Previously_Insured shows relatively high -ve correlation with 'accepted'.\n#### - Policy_sales_Channel also shows -ve correlation with 'accepted'."},{"metadata":{},"cell_type":"markdown","source":"## - Correlation matrix for \"Region Code\""},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 800\ntitle = '<b>Correlation Matrix for the dataset:</b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\n\ndf_train = df_train\nclasses = unique_sets[0]+['accepted']\n\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat//0.0001)/10000\ncorrelation_mat_norm = (correlation_mat//0.01)/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra></extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))//1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion :\n### - **As can be clearly seen in the above correlation plot(heatmap),only Region_code_28.0 shows a relatively high +ve correlation with 'accepted' label ; hence, it is an important feature to consider for classification.**"},{"metadata":{},"cell_type":"markdown","source":"# - Useful Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from the above plots, the Features that seems to be useful are : \nuseful_columns = ['Age', 'Driving_License','Previously_Insured',\n           'Policy_Sales_Channel', 'Vehicle_Age', 'Vehicle_Damage','Region_Code_28.0', 'accepted']\n\nprint(\"Total number of useful Features : {} \\n {}\".format(len(useful_columns),useful_columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# - Preparing Training & Testing Sets"},{"metadata":{},"cell_type":"markdown","source":"## 1. Training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_x = df_train[[x for x in useful_columns if x != 'accepted']]\ndf_train_y = df_train[['accepted']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train_x.info())\nprint()\nprint(df_train_y.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Train test Split\n<pre>\n<b>This data has been split in two parts with size of the training part being 0.9 of the total size of the dataset,and remaining is the test dataset.</b>\n</pre>"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(df_train_x, df_train_y,test_size=0.10,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Model Selection\n<pre>\n1. Model declaration.\n2. Fitting data to the Model.\n3. Making Predictions.\n</pre>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have use enseble learning model - XGBoost classifier for classification.\nclf = xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the data in the model\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction on test set.\nprediction = clf.predict(x_test)\nprint(\"1's in y_pred : {}\\n1's in y_test : {}\".format(sum(prediction),sum(np.array(y_test))[0]))\nprint(\"\\n0's in y_pred : {}\\n0's in y_test : {}\".format(len(prediction)-sum(prediction),len(prediction)-sum(np.array(y_test))[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_prob = clf.predict_proba(x_test)\nprint(prediction_prob)\n\nprint(\"\\nResult Log : \")\nprint(\"predict_proba(x_test) returns a 2-D array of probabilities of the label being classified as [0,1], for each datapoint.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# p(0) = 1-p(1)\n# So, keeping both columns of prediction_prob is redundant!!\n# Hence, we drop the 1's probabilities column and stack it with y_test; so as to draw interpretations of our model's prediction using violinplot.\n\nprediction_prob = np.array(prediction_prob)\nprediction_prob = np.hstack((prediction_prob[:,:1],y_test))\n\nprint(\"prediction_prob : \\n\\n\",prediction_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - So, basically now what prediction_prob is that it's first column tells - what is the probability that the model will predict this datapoint as 0. And the second column tells - what was the label of this datapoint actually!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(y = prediction_prob[:,0],x = prediction_prob[:,1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## - Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion : \n### we observe that : \n### For label - 0 : our model has mostly been successful in predicting it right(as the distribution of the violin plot is more dense near 1).\n### For label - 1 : our model has not been as successfull in predicting it right(as the distribution is more dense near 0.7). So, we can conclude that, although we may get a pretty good accuracy for this classification,still we might not get a good \"average F1-score\".\n\n## Why so?\n### It happens because; Our model is predicting class-0 with much more confidence than that with which it predicts the class-1. So precision and recall for our model predicting 1 is pretty \"Low\", which sets the overall F1-score average to decrease. "},{"metadata":{},"cell_type":"markdown","source":"## 4. Designing a scorer for calculating F1-Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"#designing a F1-scorer\n\ndef Custom_f1_score(y_true,y_pred):\n    \"\"\"\n    y_true : true values of the datapoints; correct values.\n    y_pred : predicted values\n    \n    return (x,y,z) : (x,y,z) f1_scores.\n    \n    x = f1_score for first class.(in binary class = 0).\n    y = f1_score for second class.(in binary class = 1).\n    z = average of the two.(z = (x+y)/2).\n    \n    Confusion_matrix:\n    \n         0   1\n      0| A | B\n         -   -\n      1| C | D\n    \n    x = (2*A)/(2*A+B+C)\n    \n    y = (2*D)/(2*D+B+C)\n    \n    \"\"\"\n    \n    f1_scores = []\n    arr = np.zeros((2,2))\n    \n    for i,j in zip(y_true.to_numpy().ravel(),y_pred):\n        arr[i][j]+=1\n    \n    denom_0 = (arr[0][0]+arr[0][1])+(arr[0][0]+arr[1][0])\n    denom_1 = (arr[1][1]+arr[0][1])+(arr[1][1]+arr[1][0])\n    \n    f1_scores.append(2*arr[0][0]/(denom_0))\n    f1_scores.append(2*arr[1][1]/(denom_1))\n    \n    return (f1_scores[0],f1_scores[1],sum(f1_scores)/2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Correctness of our F1-scorer :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cvar = Custom_f1_score(y_test,prediction)\nprint(\"using in-built metrics : {}\\nusing Custom_f1_score : {}\".format((sum(f1_score(y_test,prediction,average = None))/2),cvar[2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setting Threshold\n### <li>Setting custom Threshold over the probabilities that our model has predicted for each datapoint and then chosing the right Threshold that gives the best F1-Score."},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_scores = []\n\n#threshold is incremented with 0.01 on each iteration. \nfor threshold in np.arange(0,1.01,0.01):\n    \n    predictions = []\n    for probability in prediction_prob[:,0]:\n        \n        if(probability>threshold):\n            predictions.append(0)\n        else:\n            predictions.append(1)\n            \n    score = Custom_f1_score(y_test,predictions)\n    \n    f1_scores.append((threshold,score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To hold the f1_score for various threshold values.\nmax_list = []\n\nfor val in f1_scores:\n    print(\"Threshold value : {}\\naverage f1-score : {}\".format(val[0],val[1][2]))\n    max_list.append(val[1][2])\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Optimal Threshold : {}\".format(max_list.index(max(max_list))/100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Data Preparation For Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/Tow-Mater-Labs/test.csv')\nprint('Read Successful')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Various Encodings to perform on Test Data\n<pre>\n- Region_Code = 28.0\n- Vehicle_Age\n- Vehicle_Damage\n- Gender\n</pre>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode Region_Code 28\nencode = []\nfor val in df_test['Region_Code']:\n    \n    if(val==28.0):\n        encode.append(1)\n    else:\n        encode.append(0)\n        \ndf_test['Region_Code_28.0'] = encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode Vehicle_Age\nencode = []\nfor val in df_test['Vehicle_Age']:\n    \n    if(val == '< 1 Year'):\n        encode.append(0.5)\n    elif(val == '1-2 Year'):\n        encode.append(1.5)\n    else:\n        encode.append(2.5)\n\ndf_test['Vehicle_Age'] = encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode Vehicle_Damage\nencode = []\nfor val in df_test['Vehicle_Damage']:\n    \n    if(val == 'Yes'):\n        encode.append(1)\n    else:\n        encode.append(0)\ndf_test['Vehicle_Damage'] = encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode Gender\nencode = []\nfor val in df_test['Gender']:\n    \n    if(val=='Male'):\n        encode.append(1)\n    else:\n        encode.append(0)\n        \n        \ndf_test['Gender'] = encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions = clf.predict_proba(df_test[[x for x in useful_columns if x!='accepted']])\nprint(\"Final Probabilities : \\n\\n{}\".format(final_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## - Predictions[] will store the final Predictions done by our model on the Dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\nfor probability in final_predictions[:,0]:\n    \n    if probability>0.73 :\n        predictions.append(0)\n    else:\n        predictions.append(1)\n\nprint(\"number of 1's predicted : {}\\nTotal number of datapoints : {}\".format(sum(predictions),len(predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['accepted'] = predictions\ndf_test[['id','accepted']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = pd.read_csv('./submission.csv')\nprint(alpha['accepted'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}